{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def getListOfFiles(dirName):\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    for entry in listOfFile:\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "    return allFiles\n",
    "\n",
    "def get_csi_amplitudes(csi_value):\n",
    "    csi_amplitudes = []\n",
    "    for v in csi_value:\n",
    "        amplitude = np.absolute(v)\n",
    "        csi_amplitudes.append(amplitude)\n",
    "    return csi_amplitudes\n",
    "\n",
    "def get_data(mat_filename, transmitter, receiver, authenticated_pair = [' ',' ']):\n",
    "    annots = loadmat(mat_filename)\n",
    "    data = []\n",
    "    for i in range(len(annots['Raw_Cell_Matrix'])):\n",
    "        authenticated = 0\n",
    "        if transmitter == authenticated_pair[0] and receiver == authenticated_pair[1]:\n",
    "            authenticated = 1\n",
    "        data.append([\n",
    "            int(annots['Raw_Cell_Matrix'][i][0]['timestamp_low'][0][0][0][0]),\n",
    "            transmitter,\n",
    "            receiver,\n",
    "            annots['Raw_Cell_Matrix'][i][0]['agc'][0][0][0][0]\n",
    "            ] + get_csi_amplitudes(annots['Raw_Cell_Matrix'][i][0]['CSI'][0][0][0][0])\n",
    "            + [authenticated]\n",
    "            )\n",
    "\n",
    "    csi_columns = ['A'+ str(i) for i in range(1,31)]\n",
    "    columns = ['timestamp', 'transmitter', 'receiver', 'RSS'] + csi_columns + ['Authenticated']\n",
    "    final_data = pd.DataFrame(data, columns=columns)\n",
    "    return final_data\n",
    "\n",
    "# print(prepare_data('data.mat','S13','S21'))\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def prepare_data(directory, authenticated_pair):\n",
    "    csi_columns = ['A'+ str(i) for i in range(1,31)]\n",
    "    columns = ['timestamp', 'transmitter', 'receiver', 'RSS'] + csi_columns\n",
    "    all_data = pd.DataFrame([], columns=columns)\n",
    "    for p in getListOfFiles(Path(directory)):\n",
    "        pair = p.split('/')[1]\n",
    "        print(p, pair.split('_')[0], pair.split('_')[1])\n",
    "        data = get_data(p, pair.split('_')[0], pair.split('_')[1], authenticated_pair = authenticated_pair)\n",
    "        all_data = pd.concat([all_data, data])\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data/S19_S11/I12/S19_S11_I12_T10.mat S19 S11\n",
      "test_data/S19_S11/I12/S19_S11_I12_T8.mat S19 S11\n",
      "test_data/S19_S11/I12/S19_S11_I12_T9.mat S19 S11\n",
      "test_data/S19_S11/I12/S19_S11_I12_T1.mat S19 S11\n",
      "test_data/S19_S11/I12/S19_S11_I12_T2.mat S19 S11\n",
      "test_data/S19_S11/I12/S19_S11_I12_T3.mat S19 S11\n",
      "test_data/S19_S11/I12/S19_S11_I12_T7.mat S19 S11\n",
      "test_data/S19_S11/I12/S19_S11_I12_T6.mat S19 S11\n",
      "test_data/S19_S11/I12/S19_S11_I12_T4.mat S19 S11\n",
      "test_data/S19_S11/I12/S19_S11_I12_T5.mat S19 S11\n",
      "test_data/S19_S11/I10/S19_S11_I10_T8.mat S19 S11\n",
      "test_data/S19_S11/I10/S19_S11_I10_T9.mat S19 S11\n",
      "test_data/S19_S11/I10/S19_S11_I10_T10.mat S19 S11\n",
      "test_data/S19_S11/I10/S19_S11_I10_T4.mat S19 S11\n",
      "test_data/S19_S11/I10/S19_S11_I10_T5.mat S19 S11\n",
      "test_data/S19_S11/I10/S19_S11_I10_T7.mat S19 S11\n",
      "test_data/S19_S11/I10/S19_S11_I10_T6.mat S19 S11\n",
      "test_data/S19_S11/I10/S19_S11_I10_T2.mat S19 S11\n",
      "test_data/S19_S11/I10/S19_S11_I10_T3.mat S19 S11\n",
      "test_data/S19_S11/I10/S19_S11_I10_T1.mat S19 S11\n",
      "test_data/S19_S11/I11/S19_S11_I11_T6.mat S19 S11\n",
      "test_data/S19_S11/I11/S19_S11_I11_T7.mat S19 S11\n",
      "test_data/S19_S11/I11/S19_S11_I11_T10.mat S19 S11\n",
      "test_data/S19_S11/I11/S19_S11_I11_T5.mat S19 S11\n",
      "test_data/S19_S11/I11/S19_S11_I11_T4.mat S19 S11\n",
      "test_data/S19_S11/I11/S19_S11_I11_T1.mat S19 S11\n",
      "test_data/S19_S11/I11/S19_S11_I11_T3.mat S19 S11\n",
      "test_data/S19_S11/I11/S19_S11_I11_T2.mat S19 S11\n",
      "test_data/S19_S11/I11/S19_S11_I11_T9.mat S19 S11\n",
      "test_data/S19_S11/I11/S19_S11_I11_T8.mat S19 S11\n",
      "test_data/S13_S21/I12/S13_S21_I12_T8.mat S13 S21\n",
      "test_data/S13_S21/I12/S13_S21_I12_T9.mat S13 S21\n",
      "test_data/S13_S21/I12/S13_S21_I12_T10.mat S13 S21\n",
      "test_data/S13_S21/I12/S13_S21_I12_T1.mat S13 S21\n",
      "test_data/S13_S21/I12/S13_S21_I12_T2.mat S13 S21\n",
      "test_data/S13_S21/I12/S13_S21_I12_T3.mat S13 S21\n",
      "test_data/S13_S21/I12/S13_S21_I12_T7.mat S13 S21\n",
      "test_data/S13_S21/I12/S13_S21_I12_T6.mat S13 S21\n",
      "test_data/S13_S21/I12/S13_S21_I12_T4.mat S13 S21\n",
      "test_data/S13_S21/I12/S13_S21_I12_T5.mat S13 S21\n",
      "test_data/S13_S21/I10/S13_S21_I10_T8.mat S13 S21\n",
      "test_data/S13_S21/I10/S13_S21_I10_T9.mat S13 S21\n",
      "test_data/S13_S21/I10/S13_S21_I10_T10.mat S13 S21\n",
      "test_data/S13_S21/I10/S13_S21_I10_T4.mat S13 S21\n",
      "test_data/S13_S21/I10/S13_S21_I10_T5.mat S13 S21\n",
      "test_data/S13_S21/I10/S13_S21_I10_T7.mat S13 S21\n",
      "test_data/S13_S21/I10/S13_S21_I10_T6.mat S13 S21\n",
      "test_data/S13_S21/I10/S13_S21_I10_T2.mat S13 S21\n",
      "test_data/S13_S21/I10/S13_S21_I10_T3.mat S13 S21\n",
      "test_data/S13_S21/I10/S13_S21_I10_T1.mat S13 S21\n",
      "test_data/S13_S21/I11/S13_S21_I11_T6.mat S13 S21\n",
      "test_data/S13_S21/I11/S13_S21_I11_T7.mat S13 S21\n",
      "test_data/S13_S21/I11/S13_S21_I11_T5.mat S13 S21\n",
      "test_data/S13_S21/I11/S13_S21_I11_T4.mat S13 S21\n",
      "test_data/S13_S21/I11/S13_S21_I11_T1.mat S13 S21\n",
      "test_data/S13_S21/I11/S13_S21_I11_T3.mat S13 S21\n",
      "test_data/S13_S21/I11/S13_S21_I11_T10.mat S13 S21\n",
      "test_data/S13_S21/I11/S13_S21_I11_T2.mat S13 S21\n",
      "test_data/S13_S21/I11/S13_S21_I11_T9.mat S13 S21\n",
      "test_data/S13_S21/I11/S13_S21_I11_T8.mat S13 S21\n"
     ]
    }
   ],
   "source": [
    "authenticated_pair = ['S13', 'S21']\n",
    "test_data = prepare_data('./test_data',authenticated_pair = authenticated_pair)\n",
    "df_test = test_data.drop(['timestamp','transmitter', 'receiver','Authenticated'],axis = 1)\n",
    "dfy_test = test_data[['Authenticated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authenticated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Authenticated\n",
       "0            0.0\n",
       "1            0.0\n",
       "2            0.0\n",
       "3            0.0\n",
       "4            0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df_test\n",
    "Y_test = dfy_test\n",
    "Y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------RANDOM FOREST CLASSIFIER-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rf_model_class.sav'\n",
    "\n",
    "rf = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966320645905421"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50432,   980],\n",
       "       [ 2524, 50104]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9667432739245476"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "precision_score(Y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9663190701510402"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "f1_score(Y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------KNN CLASSIFIER-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'knn_model_class.sav'\n",
    "\n",
    "knn = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961005382545175"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50471,   941],\n",
       "       [ 3116, 49512]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9618310925247073"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(Y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9609978677223345"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(Y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------Logistic Regression-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'lr_model_class.sav'\n",
    "\n",
    "lr = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714436755094195"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50315,  1097],\n",
       "       [ 1874, 50754]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9715538414268147"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "precision_score(Y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714445754107475"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "f1_score(Y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------Support Vector Machine-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'svm_model_class.sav'\n",
    "\n",
    "svm = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710207612456747"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50318,  1094],\n",
       "       [ 1921, 50707]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.971145192859383"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(Y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710216225318339"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(Y_test, y_pred, average='weighted')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "090e0d5e8e0a5908084b971b27c3f3b04c7574be0362b94e1bf0f715adb968d6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
